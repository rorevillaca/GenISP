{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "800\n",
      "[ 0 77  0]\n"
     ]
    }
   ],
   "source": [
    "import rawpy\n",
    "import imageio\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "path = r\"C:/Users/Revi/Desktop/Sony/sony_train/DSC01118.ARW\"\n",
    "with rawpy.imread(path) as raw:\n",
    "    #rgb = raw.postprocess()\n",
    "    data = raw.raw_image.copy()\n",
    "    print(data[0,0])\n",
    "    #print(raw.raw_image)\n",
    "    #print(len(raw.raw_image))\n",
    "    rgb = raw.postprocess()\n",
    "    print(rgb[0,0])\n",
    "    imageio.imsave('C:/Users/Revi/Desktop/Sony/aaa.jpeg', rgb)\n",
    "    \n",
    "    #print(raw.rgb_xyz_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "width = 5496\n",
    "height = 3672\n",
    "\n",
    "with open(\"C:/Users/Revi/Desktop/Sony/sony_train/DSC01118.ARW\", \"rb\") as rawimg:\n",
    "    # Read the raw image as uint8\n",
    "    bayer_im = np.fromfile(rawimg, np.uint8, width * height).reshape(height, width)\n",
    "\n",
    "bayer_im[0,0]\n",
    "\n",
    "\n",
    "#https://cs.brown.edu/courses/csci1290/labs/lab_raw/index.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw pattern:                  [[0, 1], [3, 2]]\n",
      "CTS Matrix:\n",
      "[[ 1.0315 -0.439  -0.0937]\n",
      " [-0.4859  1.2734  0.2365]\n",
      " [-0.0734  0.1537  0.5997]\n",
      " [ 0.      0.      0.    ]]\n",
      "Color description:  b'RGBG'\n"
     ]
    }
   ],
   "source": [
    "raw_filename = 'C:/Users/Revi/Desktop/Sony/sony_train/DSC01375.ARW'\n",
    " \n",
    "with rawpy.imread(raw_filename) as raw:\n",
    "    print(f'raw pattern:                  {raw.raw_pattern.tolist()}')          # decribes the pattern of the Bayer sensor\n",
    "    print(f'CTS Matrix:')\n",
    "    print(raw.rgb_xyz_matrix)       # camera specific XYZ to camara RGB conversion matrix\n",
    "    print('Color description: ', raw.color_desc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rawpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Revi\\Desktop\\Github\\GenISP\\preprocessing.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 52>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Revi/Desktop/Github/GenISP/preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m         plt\u001b[39m.\u001b[39mimshow(image_sRGB)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Revi/Desktop/Github/GenISP/preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=48'>49</a>\u001b[0m         \u001b[39m#image_XYZ = torch.from_numpy(image_XYZ).unsqueeze(0)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/Revi/Desktop/Github/GenISP/preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=49'>50</a>\u001b[0m         \u001b[39m#return image_XYZ #Returns Tensor with size [1,H,W,C]\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/Revi/Desktop/Github/GenISP/preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=51'>52</a>\u001b[0m prep_image \u001b[39m=\u001b[39m pack_avg_cst(\u001b[39m'\u001b[39;49m\u001b[39mC:/Users/Revi/Desktop/Sony/sony_train/DSC01375.ARW\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32mc:\\Users\\Revi\\Desktop\\Github\\GenISP\\preprocessing.ipynb Cell 4\u001b[0m in \u001b[0;36mpack_avg_cst\u001b[1;34m(raw_filename)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Revi/Desktop/Github/GenISP/preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpack_avg_cst\u001b[39m(raw_filename):\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Revi/Desktop/Github/GenISP/preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39mwith\u001b[39;00m rawpy\u001b[39m.\u001b[39mimread(raw_filename) \u001b[39mas\u001b[39;00m raw:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Revi/Desktop/Github/GenISP/preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39m# Get raw image data\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Revi/Desktop/Github/GenISP/preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m         image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(raw\u001b[39m.\u001b[39mraw_image, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mdouble)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Revi/Desktop/Github/GenISP/preprocessing.ipynb#W3sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m# Get the raw pattern of the photo\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'rawpy' is not defined"
     ]
    }
   ],
   "source": [
    "#https://www.numbercrunch.de/blog/2020/12/from-numbers-to-images-raw-image-processing-with-python/\n",
    "\n",
    "def pack_avg_cst(raw_filename):\n",
    "    with rawpy.imread(raw_filename) as raw:\n",
    "        # Get raw image data\n",
    "        image = np.array(raw.raw_image, dtype=np.double)\n",
    "\n",
    "        # Get the raw pattern of the photo\n",
    "        n_colors = raw.num_colors\n",
    "        colors = np.frombuffer(raw.color_desc, dtype=np.byte)\n",
    "        pattern = np.array(raw.raw_pattern)\n",
    "        i_0 = np.where(colors[pattern] == colors[0])\n",
    "        i_1 = np.where(colors[pattern] == colors[1])\n",
    "        i_2 = np.where(colors[pattern] == colors[2])\n",
    "\n",
    "        # Pack image and average the green channels\n",
    "        image_packed = np.empty((image.shape[0]//2, image.shape[1]//2, n_colors))\n",
    "        \n",
    "        image_packed[:, :, 0] = image[i_0[0][0]::2, i_0[1][0]::2]\n",
    "        image_packed[:, :, 1]  = (image[i_1[0][0]::2, i_1[1][0]::2] + image[i_1[0][1]::2, i_1[1][1]::2]) / 2\n",
    "        image_packed[:, :, 2]  = image[i_2[0][0]::2, i_2[1][0]::2]\n",
    "\n",
    "        print(image[0,3])\n",
    "        print(image[1,2])\n",
    "        print(image_packed[0,1])\n",
    "\n",
    "        # CST Conversion\n",
    "        cst = np.array(raw.rgb_xyz_matrix[0:3, :], dtype=np.double)\n",
    "        sRGB_to_XYZ = np.array([[0.4124564, 0.3575761, 0.1804375],\n",
    "                                [0.2126729, 0.7151522, 0.0721750],\n",
    "                                [0.0193339, 0.1191920, 0.9503041]], dtype=np.double)\n",
    "        sRGB_to_cam = np.dot(cst, sRGB_to_XYZ)\n",
    "        norm = np.tile(np.sum(sRGB_to_cam, 1), (3, 1)).transpose()\n",
    "        sRGB_to_cam = sRGB_to_cam / norm\n",
    "        cam_to_sRGB = np.linalg.inv(sRGB_to_cam)\n",
    "        \n",
    "        image_sRGB = np.einsum('ij,...j', cam_to_sRGB, image_packed)  # performs the matrix-vector product for each pixel\n",
    "        # apply sRGB gamma curve\n",
    "        i = image_sRGB < 0.0031308\n",
    "        j = np.logical_not(i)\n",
    "        image_sRGB[i] = 323 / 25 * image_sRGB[i]\n",
    "        image_sRGB[j] = 211 / 200 * image_sRGB[j] ** (5 / 12) - 11 / 200\n",
    "        image_sRGB = np.clip(image_sRGB, 0, 1)\n",
    "\n",
    "        plt.axis('off')\n",
    "        plt.imshow(image_sRGB)\n",
    "            \n",
    "        \n",
    "        #image_XYZ = torch.from_numpy(image_XYZ).unsqueeze(0)\n",
    "        #return image_XYZ #Returns Tensor with size [1,H,W,C]\n",
    "\n",
    "prep_image = pack_avg_cst('C:/Users/Revi/Desktop/Sony/sony_train/DSC01375.ARW')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1012.0\n",
      "992.0\n",
      "[ 864. 1002.  944.]\n",
      "torch.Size([1, 1836, 2752, 3])\n",
      "torch.Size([1, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "prep_image = pack_avg_cst('C:/Users/Revi/Desktop/Sony/sony_train/DSC01375.ARW')\n",
    "print(prep_image.shape)\n",
    "\n",
    "def resize_256(image):\n",
    "    resized_256 = image.permute(0, 3, 1, 2) \n",
    "    resized_256 = F.interpolate(resized_256, size=(256, 256), mode='bilinear')\n",
    "    return resized_256\n",
    "\n",
    "\n",
    "resized_image = resize_256(prep_image)\n",
    "print(resized_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.ops import MLP\n",
    "class i2p(nn.Module):\n",
    "    \"\"\"\n",
    "    PyTorch version of 3-layer CNN\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 16, kernel_size = 7)\n",
    "        self.relu1 = nn.LeakyReLU()\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size = 4)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels = 16, out_channels = 32, kernel_size = 5)\n",
    "        self.relu2 = nn.LeakyReLU()\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size = 3)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels = 32, out_channels = 128, kernel_size = 3)\n",
    "        self.relu3 = nn.LeakyReLU()\n",
    "        self.maxpool3 = nn.MaxPool2d(kernel_size = 2)\n",
    "        \n",
    "        self.aap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.mlp = MLP(in_channels=128,hidden_channels=[3])\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        x = x.float()\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu3(x)\n",
    "        x = self.maxpool3(x)\n",
    "\n",
    "        print(x.shape)\n",
    "        x = self.aap(x)\n",
    "        print(x.shape)\n",
    "        x = x.flatten()\n",
    "        print(x.shape)\n",
    "\n",
    "        x = self.mlp(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 8, 8])\n",
      "torch.Size([1, 128, 1, 1])\n",
      "torch.Size([128])\n",
      "tensor([ 330.7601,  -83.8726, -270.8345], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "conv_wb = i2p()\n",
    "y = conv_wb.forward(resized_image)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'raw_filename' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\Revi\\Desktop\\Github\\GenISP\\preprocessing.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/Revi/Desktop/Github/GenISP/preprocessing.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m rawpy\u001b[39m.\u001b[39mimread(raw_filename) \u001b[39mas\u001b[39;00m raw:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Revi/Desktop/Github/GenISP/preprocessing.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# get raw image data\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Revi/Desktop/Github/GenISP/preprocessing.ipynb#X10sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(raw\u001b[39m.\u001b[39mraw_image, dtype\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mdouble)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/Revi/Desktop/Github/GenISP/preprocessing.ipynb#X10sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39m# subtract black levels and normalize to interval [0..1]\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'raw_filename' is not defined"
     ]
    }
   ],
   "source": [
    "with rawpy.imread(raw_filename) as raw:\n",
    "    # get raw image data\n",
    "    image = np.array(raw.raw_image, dtype=np.double)\n",
    "    # subtract black levels and normalize to interval [0..1]\n",
    "    black = np.reshape(np.array(raw.black_level_per_channel, dtype=np.double), (2, 2))\n",
    "    black = np.tile(black, (image.shape[0]//2, image.shape[1]//2))\n",
    "    image = (image - black) / (raw.white_level - black)\n",
    "    # find the positions of the three (red, green and blue) or four base colors within the Bayer pattern\n",
    "    n_colors = raw.num_colors\n",
    "    colors = np.frombuffer(raw.color_desc, dtype=np.byte)\n",
    "    pattern = np.array(raw.raw_pattern)\n",
    "    index_0 = np.where(colors[pattern] == colors[0])\n",
    "    index_1 = np.where(colors[pattern] == colors[1])\n",
    "    index_2 = np.where(colors[pattern] == colors[2])\n",
    "    index_3 = np.where(colors[pattern] == colors[3])\n",
    "    # apply white balance, normalize white balance coefficients to the 2nd coefficient, which is ususally the coefficient for green\n",
    "    wb_c = raw.camera_whitebalance \n",
    "    wb = np.zeros((2, 2), dtype=np.double) \n",
    "    wb[index_0] = wb_c[0] / wb_c[1]\n",
    "    wb[index_1] = wb_c[1] / wb_c[1]\n",
    "    wb[index_2] = wb_c[2] / wb_c[1]\n",
    "    if n_colors == 4:\n",
    "        wb[index_3] = wb_c[3] / wb_c[1]\n",
    "    wb = np.tile(wb, (image.shape[0]//2, image.shape[1]//2))\n",
    "    image_wb = np.clip(image * wb, 0, 1)\n",
    "    # demosaic via downsampling\n",
    "    image_demosaiced = np.empty((image_wb.shape[0]//2, image_wb.shape[1]//2, n_colors))\n",
    "    if n_colors == 3:\n",
    "        image_demosaiced[:, :, 0] = image_wb[index_0[0][0]::2, index_0[1][0]::2]\n",
    "        image_demosaiced[:, :, 1]  = (image_wb[index_1[0][0]::2, index_1[1][0]::2] + image_wb[index_1[0][1]::2, index_1[1][1]::2]) / 2\n",
    "        image_demosaiced[:, :, 2]  = image_wb[index_2[0][0]::2, index_2[1][0]::2]\n",
    "    else: # n_colors == 4\n",
    "        image_demosaiced[:, :, 0] = image_wb[index_0[0][0]::2, index_0[1][0]::2]\n",
    "        image_demosaiced[:, :, 1] = image_wb[index_1[0][0]::2, index_1[1][0]::2]\n",
    "        image_demosaiced[:, :, 2] = image_wb[index_2[0][0]::2, index_2[1][0]::2]\n",
    "        image_demosaiced[:, :, 3] = image_wb[index_3[0][0]::2, index_3[1][0]::2]\n",
    "    # convert to linear sRGB, calculate the matrix that transforms sRGB into the camera's primary color components and invert this matrix to perform the inverse transformation\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
